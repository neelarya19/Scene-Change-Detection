{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uO0H0sBHK2fJ",
    "outputId": "f1e1722e-8ece-463b-de83-4d174718eb90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Rdpo-NzKbdx",
    "outputId": "705d0ebc-90ba-457c-e9c2-c2ecec76bd80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 21 21:22:42 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   55C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IQhlgyNLC8C",
    "outputId": "2c8a6fce-2465-4c72-a79f-d6ccc0deb9b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/a2/5ccf0a418eb22e0a2ae9edc1e7f5456d0a4b8b49524572897564b4030a9b/tensorflow_gpu-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3MB)\n",
      "\u001b[K     |████████████████████████████████| 454.3MB 35kB/s \n",
      "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/78/b27f73e923becc6e79e18fe112cf75e3200d1ee35b0dba8fa46181bce56c/tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462kB)\n",
      "\u001b[K     |████████████████████████████████| 471kB 44.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.36.2)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
      "Collecting grpcio~=1.34.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/d1/f38a91d8724706427fe973a7dfa11e938cee98aa7196b03d870a25a08bab/grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0MB 41.1MB/s \n",
      "\u001b[?25hCollecting h5py~=3.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/74/9eae2bedd8201ab464308f42c601a12d79727a1c87f0c867fdefb212c6cf/h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0MB 47.5MB/s \n",
      "\u001b[?25hCollecting gast==0.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/e7/53bc896aa4e11a87aac10a625c676b3a3d57d1c8d9929e4809d31fa0b7d5/keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 46.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.12.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12.1)\n",
      "Collecting tensorboard~=2.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/f5/7feea02a3fb54d5db827ac4b822a7ba8933826b36de21880518250b8733a/tensorboard-2.5.0-py3-none-any.whl (6.0MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0MB 42.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.7.4.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.12.4)\n",
      "Collecting cached-property; python_version < \"3.8\"\n",
      "  Downloading https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/f9/802efd84988bffd9f644c03b6e66fde8e76c3aa33db4279ddd11c5d61f4b/tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9MB 48.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (2.0.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (1.30.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (2.23.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (56.1.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (0.4.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (4.7.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow-gpu) (4.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (1.24.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow-gpu) (3.4.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu) (3.1.0)\n",
      "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.4.1 has requirement grpcio~=1.32.0, but you'll have grpcio 1.34.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.4.1 has requirement h5py~=2.10.0, but you'll have h5py 3.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorflow-estimator<2.5.0,>=2.4.0, but you'll have tensorflow-estimator 2.5.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorflow-estimator, grpcio, cached-property, h5py, gast, keras-nightly, tensorboard-data-server, tensorboard, tensorflow-gpu\n",
      "  Found existing installation: tensorflow-estimator 2.4.0\n",
      "    Uninstalling tensorflow-estimator-2.4.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
      "  Found existing installation: grpcio 1.32.0\n",
      "    Uninstalling grpcio-1.32.0:\n",
      "      Successfully uninstalled grpcio-1.32.0\n",
      "  Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "  Found existing installation: tensorboard 2.4.1\n",
      "    Uninstalling tensorboard-2.4.1:\n",
      "      Successfully uninstalled tensorboard-2.4.1\n",
      "Successfully installed cached-property-1.5.2 gast-0.4.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorflow-estimator-2.5.0 tensorflow-gpu-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFdarjSMGpQp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIgDXY_NJvxC"
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('/content/drive/MyDrive/dataset/Dataset2012/train_change_dete.csv',encoding='utf-8')\n",
    "test=pd.read_csv('/content/drive/MyDrive/dataset/Dataset2012/test_change_dete.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vs_RaEEXrsve",
    "outputId": "12963ccf-6280-4d82-cc4b-455e786ac0fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_AX_2PfBMUDv"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "train_data=[]\n",
    "train_labels=[]\n",
    "\n",
    "test_data=[]\n",
    "test_labels=[]\n",
    "\n",
    "for i in range(len(train)):\n",
    "    print(train['Images'][i])\n",
    "    image = cv2.imread(train['Images'][i])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    train_data.append(image)\n",
    "    if(train['label'][i]=='No Change'):\n",
    "        train_labels.append(0)\n",
    "    elif(train['label'][i]=='Slight Change'):\n",
    "        train_labels.append(1)\n",
    "    else:\n",
    "        train_labels.append(2)\n",
    "\n",
    "train_data=np.array(train_data)/255.0\n",
    "train_labels=np.array(train_labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eKIY48u9Y6Si"
   },
   "outputs": [],
   "source": [
    "for j in range(len(test)):\n",
    "    \n",
    "    image = cv2.imread(train['Images'][j])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    test_data.append(image)\n",
    "    if(train['label'][j]=='No Change'):\n",
    "        test_labels.append(0)\n",
    "    elif(train['label'][j]=='Slight Change'):\n",
    "        test_labels.append(1)\n",
    "    else:\n",
    "        test_labels.append(2)\n",
    "\n",
    "\n",
    "\n",
    "test_data=np.array(test_data)/255.0\n",
    "test_labels=np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TcPVz0ApQ3d1",
    "outputId": "1d17d763-b653-48d0-cf44-7ef80406a216"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.21176471 0.24313725 0.18431373]\n",
      "   [0.09803922 0.12941176 0.07058824]\n",
      "   [0.10980392 0.14117647 0.08235294]\n",
      "   ...\n",
      "   [0.21960784 0.25098039 0.29019608]\n",
      "   [0.25882353 0.30588235 0.36078431]\n",
      "   [0.2        0.25098039 0.31372549]]\n",
      "\n",
      "  [[0.15294118 0.18431373 0.1254902 ]\n",
      "   [0.09019608 0.12156863 0.0627451 ]\n",
      "   [0.10588235 0.1372549  0.07843137]\n",
      "   ...\n",
      "   [0.45098039 0.48627451 0.52156863]\n",
      "   [0.48627451 0.52941176 0.58039216]\n",
      "   [0.41960784 0.46666667 0.53333333]]\n",
      "\n",
      "  [[0.1254902  0.15686275 0.09803922]\n",
      "   [0.08235294 0.11372549 0.05490196]\n",
      "   [0.05490196 0.08627451 0.02745098]\n",
      "   ...\n",
      "   [0.45098039 0.47843137 0.51372549]\n",
      "   [0.5372549  0.57647059 0.62745098]\n",
      "   [0.53333333 0.58039216 0.64313725]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.52156863 0.51764706 0.49803922]\n",
      "   [0.50196078 0.49411765 0.47843137]\n",
      "   [0.49411765 0.49019608 0.47058824]\n",
      "   ...\n",
      "   [0.40392157 0.34117647 0.31372549]\n",
      "   [0.41176471 0.35294118 0.3254902 ]\n",
      "   [0.46666667 0.40392157 0.37647059]]\n",
      "\n",
      "  [[0.50196078 0.50196078 0.47058824]\n",
      "   [0.41176471 0.41176471 0.38039216]\n",
      "   [0.35686275 0.35294118 0.3254902 ]\n",
      "   ...\n",
      "   [0.35686275 0.30588235 0.2745098 ]\n",
      "   [0.42745098 0.37647059 0.34509804]\n",
      "   [0.41960784 0.36862745 0.3372549 ]]\n",
      "\n",
      "  [[0.34901961 0.34901961 0.31764706]\n",
      "   [0.25882353 0.25882353 0.22745098]\n",
      "   [0.24705882 0.24705882 0.21568627]\n",
      "   ...\n",
      "   [0.35294118 0.30196078 0.27058824]\n",
      "   [0.41568627 0.36470588 0.33333333]\n",
      "   [0.41176471 0.36078431 0.32941176]]]\n",
      "\n",
      "\n",
      " [[[0.19607843 0.22352941 0.17254902]\n",
      "   [0.09803922 0.12941176 0.07843137]\n",
      "   [0.10588235 0.1372549  0.08627451]\n",
      "   ...\n",
      "   [0.29411765 0.34901961 0.39215686]\n",
      "   [0.18431373 0.25490196 0.31372549]\n",
      "   [0.21568627 0.28627451 0.36078431]]\n",
      "\n",
      "  [[0.16862745 0.2        0.14901961]\n",
      "   [0.08627451 0.11764706 0.06666667]\n",
      "   [0.07058824 0.10196078 0.05098039]\n",
      "   ...\n",
      "   [0.46666667 0.50980392 0.55294118]\n",
      "   [0.44705882 0.50980392 0.56862745]\n",
      "   [0.40784314 0.4745098  0.54901961]]\n",
      "\n",
      "  [[0.11764706 0.14901961 0.09803922]\n",
      "   [0.08235294 0.11372549 0.0627451 ]\n",
      "   [0.05098039 0.08235294 0.03137255]\n",
      "   ...\n",
      "   [0.36078431 0.39607843 0.43921569]\n",
      "   [0.52156863 0.56470588 0.62745098]\n",
      "   [0.52941176 0.58431373 0.65490196]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.54117647 0.54509804 0.52156863]\n",
      "   [0.51372549 0.51764706 0.49411765]\n",
      "   [0.49411765 0.49803922 0.4745098 ]\n",
      "   ...\n",
      "   [0.38039216 0.3254902  0.29803922]\n",
      "   [0.4        0.34117647 0.31372549]\n",
      "   [0.47058824 0.41176471 0.38431373]]\n",
      "\n",
      "  [[0.45882353 0.4627451  0.43137255]\n",
      "   [0.38431373 0.38823529 0.35686275]\n",
      "   [0.35294118 0.35686275 0.3254902 ]\n",
      "   ...\n",
      "   [0.32941176 0.27843137 0.24705882]\n",
      "   [0.39607843 0.34509804 0.31372549]\n",
      "   [0.43137255 0.38039216 0.34901961]]\n",
      "\n",
      "  [[0.33333333 0.3372549  0.30588235]\n",
      "   [0.25882353 0.2627451  0.23137255]\n",
      "   [0.2627451  0.26666667 0.23529412]\n",
      "   ...\n",
      "   [0.34117647 0.29019608 0.25882353]\n",
      "   [0.44313725 0.39215686 0.36078431]\n",
      "   [0.41568627 0.36470588 0.33333333]]]\n",
      "\n",
      "\n",
      " [[[0.18823529 0.21960784 0.16078431]\n",
      "   [0.10196078 0.13333333 0.0745098 ]\n",
      "   [0.10980392 0.14117647 0.08235294]\n",
      "   ...\n",
      "   [0.23529412 0.29019608 0.33333333]\n",
      "   [0.20784314 0.2745098  0.3372549 ]\n",
      "   [0.17647059 0.24313725 0.32156863]]\n",
      "\n",
      "  [[0.18039216 0.21568627 0.15294118]\n",
      "   [0.09803922 0.12941176 0.07058824]\n",
      "   [0.0745098  0.10588235 0.04705882]\n",
      "   ...\n",
      "   [0.43529412 0.48235294 0.5254902 ]\n",
      "   [0.50196078 0.56862745 0.62745098]\n",
      "   [0.47843137 0.54509804 0.61960784]]\n",
      "\n",
      "  [[0.12941176 0.16078431 0.10196078]\n",
      "   [0.08627451 0.11764706 0.05882353]\n",
      "   [0.05098039 0.07843137 0.02352941]\n",
      "   ...\n",
      "   [0.3372549  0.37254902 0.41176471]\n",
      "   [0.47058824 0.51764706 0.57647059]\n",
      "   [0.56470588 0.61960784 0.69411765]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.53333333 0.5372549  0.51764706]\n",
      "   [0.52156863 0.5254902  0.50588235]\n",
      "   [0.50196078 0.50588235 0.48627451]\n",
      "   ...\n",
      "   [0.40784314 0.34901961 0.32156863]\n",
      "   [0.4        0.34509804 0.31764706]\n",
      "   [0.48627451 0.42745098 0.4       ]]\n",
      "\n",
      "  [[0.45490196 0.45882353 0.43921569]\n",
      "   [0.38823529 0.39215686 0.37254902]\n",
      "   [0.36078431 0.36470588 0.34509804]\n",
      "   ...\n",
      "   [0.35294118 0.29803922 0.27058824]\n",
      "   [0.40392157 0.35294118 0.32156863]\n",
      "   [0.4745098  0.41960784 0.38823529]]\n",
      "\n",
      "  [[0.34509804 0.34901961 0.32941176]\n",
      "   [0.25490196 0.25882353 0.23921569]\n",
      "   [0.26666667 0.27058824 0.25098039]\n",
      "   ...\n",
      "   [0.34509804 0.29411765 0.2627451 ]\n",
      "   [0.45098039 0.4        0.36862745]\n",
      "   [0.42352941 0.37254902 0.34117647]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.00392157 0.00392157 0.00392157]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.00392157 0.00392157 0.00392157]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.02352941 0.01960784 0.01176471]\n",
      "   [0.02352941 0.01960784 0.01176471]\n",
      "   [0.02352941 0.01960784 0.01176471]\n",
      "   ...\n",
      "   [0.34901961 0.23137255 0.12941176]\n",
      "   [0.34901961 0.23137255 0.12941176]\n",
      "   [0.35294118 0.23529412 0.13333333]]\n",
      "\n",
      "  [[0.02352941 0.01960784 0.01176471]\n",
      "   [0.02352941 0.01960784 0.01176471]\n",
      "   [0.02352941 0.01960784 0.01176471]\n",
      "   ...\n",
      "   [0.33333333 0.22352941 0.12941176]\n",
      "   [0.34117647 0.22352941 0.1254902 ]\n",
      "   [0.34117647 0.22352941 0.12156863]]\n",
      "\n",
      "  [[0.02352941 0.01960784 0.01176471]\n",
      "   [0.02352941 0.01960784 0.01176471]\n",
      "   [0.02352941 0.01960784 0.01176471]\n",
      "   ...\n",
      "   [0.31764706 0.20784314 0.11764706]\n",
      "   [0.3254902  0.21176471 0.12156863]\n",
      "   [0.33333333 0.21568627 0.11764706]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.01568627 0.01960784 0.        ]\n",
      "   [0.01568627 0.01960784 0.        ]\n",
      "   [0.01960784 0.02352941 0.00784314]\n",
      "   ...\n",
      "   [0.01960784 0.02352941 0.00392157]\n",
      "   [0.01960784 0.02352941 0.00392157]\n",
      "   [0.01960784 0.02352941 0.00392157]]\n",
      "\n",
      "  [[0.01568627 0.01960784 0.        ]\n",
      "   [0.01568627 0.01960784 0.        ]\n",
      "   [0.01960784 0.02745098 0.00392157]\n",
      "   ...\n",
      "   [0.01568627 0.01960784 0.        ]\n",
      "   [0.01568627 0.01960784 0.        ]\n",
      "   [0.01568627 0.01960784 0.        ]]\n",
      "\n",
      "  [[0.01568627 0.01960784 0.        ]\n",
      "   [0.01568627 0.01960784 0.        ]\n",
      "   [0.01568627 0.01960784 0.        ]\n",
      "   ...\n",
      "   [0.01568627 0.01960784 0.        ]\n",
      "   [0.01568627 0.01960784 0.        ]\n",
      "   [0.01568627 0.01960784 0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kQv-sjlmQ9-w",
    "outputId": "54100344-9262-4eb3-ecd8-222d18e8166c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "To5UC7dqRKSe",
    "outputId": "47b362ab-1f19-4ea5-90ca-20a4f6d745c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.21176471 0.24313725 0.18431373]\n",
      "   [0.09803922 0.12941176 0.07058824]\n",
      "   [0.10980392 0.14117647 0.08235294]\n",
      "   ...\n",
      "   [0.21960784 0.25098039 0.29019608]\n",
      "   [0.25882353 0.30588235 0.36078431]\n",
      "   [0.2        0.25098039 0.31372549]]\n",
      "\n",
      "  [[0.15294118 0.18431373 0.1254902 ]\n",
      "   [0.09019608 0.12156863 0.0627451 ]\n",
      "   [0.10588235 0.1372549  0.07843137]\n",
      "   ...\n",
      "   [0.45098039 0.48627451 0.52156863]\n",
      "   [0.48627451 0.52941176 0.58039216]\n",
      "   [0.41960784 0.46666667 0.53333333]]\n",
      "\n",
      "  [[0.1254902  0.15686275 0.09803922]\n",
      "   [0.08235294 0.11372549 0.05490196]\n",
      "   [0.05490196 0.08627451 0.02745098]\n",
      "   ...\n",
      "   [0.45098039 0.47843137 0.51372549]\n",
      "   [0.5372549  0.57647059 0.62745098]\n",
      "   [0.53333333 0.58039216 0.64313725]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.52156863 0.51764706 0.49803922]\n",
      "   [0.50196078 0.49411765 0.47843137]\n",
      "   [0.49411765 0.49019608 0.47058824]\n",
      "   ...\n",
      "   [0.40392157 0.34117647 0.31372549]\n",
      "   [0.41176471 0.35294118 0.3254902 ]\n",
      "   [0.46666667 0.40392157 0.37647059]]\n",
      "\n",
      "  [[0.50196078 0.50196078 0.47058824]\n",
      "   [0.41176471 0.41176471 0.38039216]\n",
      "   [0.35686275 0.35294118 0.3254902 ]\n",
      "   ...\n",
      "   [0.35686275 0.30588235 0.2745098 ]\n",
      "   [0.42745098 0.37647059 0.34509804]\n",
      "   [0.41960784 0.36862745 0.3372549 ]]\n",
      "\n",
      "  [[0.34901961 0.34901961 0.31764706]\n",
      "   [0.25882353 0.25882353 0.22745098]\n",
      "   [0.24705882 0.24705882 0.21568627]\n",
      "   ...\n",
      "   [0.35294118 0.30196078 0.27058824]\n",
      "   [0.41568627 0.36470588 0.33333333]\n",
      "   [0.41176471 0.36078431 0.32941176]]]\n",
      "\n",
      "\n",
      " [[[0.19607843 0.22352941 0.17254902]\n",
      "   [0.09803922 0.12941176 0.07843137]\n",
      "   [0.10588235 0.1372549  0.08627451]\n",
      "   ...\n",
      "   [0.29411765 0.34901961 0.39215686]\n",
      "   [0.18431373 0.25490196 0.31372549]\n",
      "   [0.21568627 0.28627451 0.36078431]]\n",
      "\n",
      "  [[0.16862745 0.2        0.14901961]\n",
      "   [0.08627451 0.11764706 0.06666667]\n",
      "   [0.07058824 0.10196078 0.05098039]\n",
      "   ...\n",
      "   [0.46666667 0.50980392 0.55294118]\n",
      "   [0.44705882 0.50980392 0.56862745]\n",
      "   [0.40784314 0.4745098  0.54901961]]\n",
      "\n",
      "  [[0.11764706 0.14901961 0.09803922]\n",
      "   [0.08235294 0.11372549 0.0627451 ]\n",
      "   [0.05098039 0.08235294 0.03137255]\n",
      "   ...\n",
      "   [0.36078431 0.39607843 0.43921569]\n",
      "   [0.52156863 0.56470588 0.62745098]\n",
      "   [0.52941176 0.58431373 0.65490196]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.54117647 0.54509804 0.52156863]\n",
      "   [0.51372549 0.51764706 0.49411765]\n",
      "   [0.49411765 0.49803922 0.4745098 ]\n",
      "   ...\n",
      "   [0.38039216 0.3254902  0.29803922]\n",
      "   [0.4        0.34117647 0.31372549]\n",
      "   [0.47058824 0.41176471 0.38431373]]\n",
      "\n",
      "  [[0.45882353 0.4627451  0.43137255]\n",
      "   [0.38431373 0.38823529 0.35686275]\n",
      "   [0.35294118 0.35686275 0.3254902 ]\n",
      "   ...\n",
      "   [0.32941176 0.27843137 0.24705882]\n",
      "   [0.39607843 0.34509804 0.31372549]\n",
      "   [0.43137255 0.38039216 0.34901961]]\n",
      "\n",
      "  [[0.33333333 0.3372549  0.30588235]\n",
      "   [0.25882353 0.2627451  0.23137255]\n",
      "   [0.2627451  0.26666667 0.23529412]\n",
      "   ...\n",
      "   [0.34117647 0.29019608 0.25882353]\n",
      "   [0.44313725 0.39215686 0.36078431]\n",
      "   [0.41568627 0.36470588 0.33333333]]]\n",
      "\n",
      "\n",
      " [[[0.18823529 0.21960784 0.16078431]\n",
      "   [0.10196078 0.13333333 0.0745098 ]\n",
      "   [0.10980392 0.14117647 0.08235294]\n",
      "   ...\n",
      "   [0.23529412 0.29019608 0.33333333]\n",
      "   [0.20784314 0.2745098  0.3372549 ]\n",
      "   [0.17647059 0.24313725 0.32156863]]\n",
      "\n",
      "  [[0.18039216 0.21568627 0.15294118]\n",
      "   [0.09803922 0.12941176 0.07058824]\n",
      "   [0.0745098  0.10588235 0.04705882]\n",
      "   ...\n",
      "   [0.43529412 0.48235294 0.5254902 ]\n",
      "   [0.50196078 0.56862745 0.62745098]\n",
      "   [0.47843137 0.54509804 0.61960784]]\n",
      "\n",
      "  [[0.12941176 0.16078431 0.10196078]\n",
      "   [0.08627451 0.11764706 0.05882353]\n",
      "   [0.05098039 0.07843137 0.02352941]\n",
      "   ...\n",
      "   [0.3372549  0.37254902 0.41176471]\n",
      "   [0.47058824 0.51764706 0.57647059]\n",
      "   [0.56470588 0.61960784 0.69411765]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.53333333 0.5372549  0.51764706]\n",
      "   [0.52156863 0.5254902  0.50588235]\n",
      "   [0.50196078 0.50588235 0.48627451]\n",
      "   ...\n",
      "   [0.40784314 0.34901961 0.32156863]\n",
      "   [0.4        0.34509804 0.31764706]\n",
      "   [0.48627451 0.42745098 0.4       ]]\n",
      "\n",
      "  [[0.45490196 0.45882353 0.43921569]\n",
      "   [0.38823529 0.39215686 0.37254902]\n",
      "   [0.36078431 0.36470588 0.34509804]\n",
      "   ...\n",
      "   [0.35294118 0.29803922 0.27058824]\n",
      "   [0.40392157 0.35294118 0.32156863]\n",
      "   [0.4745098  0.41960784 0.38823529]]\n",
      "\n",
      "  [[0.34509804 0.34901961 0.32941176]\n",
      "   [0.25490196 0.25882353 0.23921569]\n",
      "   [0.26666667 0.27058824 0.25098039]\n",
      "   ...\n",
      "   [0.34509804 0.29411765 0.2627451 ]\n",
      "   [0.45098039 0.4        0.36862745]\n",
      "   [0.42352941 0.37254902 0.34117647]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.00392157 0.00392157 0.00392157]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.00392157 0.00392157 0.00392157]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.02352941 0.01960784 0.01176471]\n",
      "   [0.02352941 0.01960784 0.01176471]\n",
      "   [0.02352941 0.01960784 0.01176471]\n",
      "   ...\n",
      "   [0.34901961 0.23137255 0.12941176]\n",
      "   [0.34901961 0.23137255 0.12941176]\n",
      "   [0.35294118 0.23529412 0.13333333]]\n",
      "\n",
      "  [[0.02352941 0.01960784 0.01176471]\n",
      "   [0.02352941 0.01960784 0.01176471]\n",
      "   [0.02352941 0.01960784 0.01176471]\n",
      "   ...\n",
      "   [0.33333333 0.22352941 0.12941176]\n",
      "   [0.34117647 0.22352941 0.1254902 ]\n",
      "   [0.34117647 0.22352941 0.12156863]]\n",
      "\n",
      "  [[0.02352941 0.01960784 0.01176471]\n",
      "   [0.02352941 0.01960784 0.01176471]\n",
      "   [0.02352941 0.01960784 0.01176471]\n",
      "   ...\n",
      "   [0.31764706 0.20784314 0.11764706]\n",
      "   [0.3254902  0.21176471 0.12156863]\n",
      "   [0.33333333 0.21568627 0.11764706]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.01568627 0.01960784 0.        ]\n",
      "   [0.01568627 0.01960784 0.        ]\n",
      "   [0.01960784 0.02352941 0.00784314]\n",
      "   ...\n",
      "   [0.01960784 0.02352941 0.00392157]\n",
      "   [0.01960784 0.02352941 0.00392157]\n",
      "   [0.01960784 0.02352941 0.00392157]]\n",
      "\n",
      "  [[0.01568627 0.01960784 0.        ]\n",
      "   [0.01568627 0.01960784 0.        ]\n",
      "   [0.01960784 0.02745098 0.00392157]\n",
      "   ...\n",
      "   [0.01568627 0.01960784 0.        ]\n",
      "   [0.01568627 0.01960784 0.        ]\n",
      "   [0.01568627 0.01960784 0.        ]]\n",
      "\n",
      "  [[0.01568627 0.01960784 0.        ]\n",
      "   [0.01568627 0.01960784 0.        ]\n",
      "   [0.01568627 0.01960784 0.        ]\n",
      "   ...\n",
      "   [0.01568627 0.01960784 0.        ]\n",
      "   [0.01568627 0.01960784 0.        ]\n",
      "   [0.01568627 0.01960784 0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i1Ux-Z-jRO4J",
    "outputId": "53d0f3af-1bc0-4da8-c258-16f7c33f22ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jv0XwosaKbeB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BWgN4HOcKbeC",
    "outputId": "8cf4f73d-202a-45e1-d478-ff0921d1a49c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 75267     \n",
      "=================================================================\n",
      "Total params: 14,789,955\n",
      "Trainable params: 75,267\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = [224, 224]\n",
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "for layer in vgg.layers:\n",
    "  layer.trainable = False\n",
    "x = Flatten()(vgg.output)\n",
    "prediction = Dense(3, activation='softmax')(x)\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "model.summary()\n",
    "model.compile(\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gzqBU3tCKbeD",
    "outputId": "b745189d-16bd-4c66-f01b-cb702ad6698f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1899/1899 [==============================] - 868s 457ms/step - loss: 1.7182 - accuracy: 0.8515 - val_loss: 2.1382 - val_accuracy: 0.9200\n",
      "Epoch 2/5\n",
      "1899/1899 [==============================] - 858s 452ms/step - loss: 1.6094 - accuracy: 0.8763 - val_loss: 2.6362 - val_accuracy: 0.9200\n",
      "Epoch 3/5\n",
      "1899/1899 [==============================] - 840s 442ms/step - loss: 1.6565 - accuracy: 0.8899 - val_loss: 0.9661 - val_accuracy: 0.7400\n",
      "Epoch 4/5\n",
      "1899/1899 [==============================] - 838s 441ms/step - loss: 1.1987 - accuracy: 0.9073 - val_loss: 1.8393 - val_accuracy: 0.9200\n",
      "Epoch 5/5\n",
      "1899/1899 [==============================] - 836s 440ms/step - loss: 1.4031 - accuracy: 0.9042 - val_loss: 1.0936 - val_accuracy: 0.8600\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "earlyStopping = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=3,\n",
    "                              verbose=1)\n",
    "\n",
    "callback_early_stop_reduceLROnPlateau=[earlyStopping]\n",
    "\n",
    "\n",
    "EPOCHS = 5\n",
    "BS = 1\n",
    "progess = model.fit(train_data,train_labels, batch_size=BS,epochs=EPOCHS, callbacks=callback_early_stop_reduceLROnPlateau,validation_split=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7ueocLQ8QEY"
   },
   "outputs": [],
   "source": [
    "predictions=model.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nV0CzKtbWPDs"
   },
   "outputs": [],
   "source": [
    "y_classes = predictions.argmax(axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkGA1byCUQEr",
    "outputId": "3df56290-dfca-48b4-f554-fdc734ce7400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9645641389085755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       207\n",
      "           1       0.99      0.98      0.98      1159\n",
      "           2       0.65      0.58      0.61        45\n",
      "\n",
      "    accuracy                           0.96      1411\n",
      "   macro avg       0.85      0.84      0.85      1411\n",
      "weighted avg       0.96      0.96      0.96      1411\n",
      "\n",
      "[[ 201    5    1]\n",
      " [  12 1134   13]\n",
      " [   7   12   26]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "correct_count = 0.0\n",
    "accuracy=accuracy_score(test_labels,y_classes)\n",
    "# for i in range(len(test_labels)):\n",
    "#     if predictions[i] == test_labels[i]:\n",
    "#         correct_count += 1.0\n",
    "# accuracy = correct_count/float(len(test_labels))\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(test_labels, y_classes))\n",
    "print(confusion_matrix(test_labels, y_classes))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "change_detection.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
